<document xmlns="http://cnx.rice.edu/cnxml">
  <title>Fear, the Precautionary Principle, and the Four Dimensions of Risk</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m81959</md:content-id>
  <md:title>Fear, the Precautionary Principle, and the Four Dimensions of Risk</md:title>
  <md:abstract>This module first examines the emotion of fear and then examines both the Precautionary Principle and Risk theories and practices as "outgrowths" of this emotion.  It is based loosely on a prior module by the author, "Ethical Issues for Risk Management in Business."  The author would like to acknowledge the National Science Foundation for its support through the grant, "Cultivating Responsible Wellbeing in STEM: Social Engagement Through Personal Ethics", NSF SES 1449489.</md:abstract>
  <md:uuid>639f85e8-be2b-4810-87d6-7b0787bc37ea</md:uuid>
</metadata>

<content>
    <para id="import-auto-idm682641728">This is a first version.  There are still a few bugs to be worked out.  This module is one of five that center on emotions, their underlying and supporting theories, and the virtues in which they can be inscribed.  Emotions provide an effective way to combat the disengagement of STEM students; studies are out that indicate that STEM students become increasingly disengaged from social, ethical, and global issues as their undergraduate studies progress.  Erin Cech argues that this stems from three ideologies characteristic of the STEM curriculum: depoliticization, the devaluation of the social, and meritocracy.  (See “Culture of Disengagement in Engineering Education?” Erin A. Cech. Science, Technology, and Human Values 2014, 39 (1))  Given this disengagement, emotions seem a promising route for reengagement.  You will find in this module reasons for reflecting on fear, using the supporting theories of risk and precaution to support and guide this emotion, and integrating fear into the supporting structure of the virtue of moral courage.</para><para id="import-auto-idm862967152"><emphasis effect="bold">I. Introduction</emphasis>: </para>
    <para id="import-auto-idm605137408">In the mid-1990s, the U.S. Navy proposed building a radar facility near Lajas, Puerto Rico to monitor drug trafficking in the Caribbean as well as illegal immigration from the Dominican Republic and Haiti.  Opposition to this project emerged and led to public hearings that took place in Lajas in the mid-1990s.  Much of the opposition centered on the electromagnetic fields (EMFs) that would be generated by radar facilities and the public’s fear of the adverse health effects of exposure to these.  </para>
    <para id="import-auto-idm352528544">Engineers took stands on both sides of this issue.  Those supporting the project expressed exasperation over what they perceived as the tendency of the public to give way to irrational fear in the face of new technology.  They saw the public’s perception of the risks associated with exposure to EMFs as tantamount to a stampede to irrationality driven by fear rather than rational, scientific assessment.  Since no risk has been irrefutably attributed to radar facilities and the EMFs they generate, the project should be allowed to continue as planned.</para>
    <para id="import-auto-idm452154624">Engineers who opposed the radar facilities, held that emotions like fear can be grounded in rational appraisals that assess the impact of this technology on individual and community well-being.  Sabine Roeser provides a general statement of this position (Roeser 2018).  For example, fear can be tied to a judicious use of the Precautionary Principle: this principle counsels that, in the face of uncertainty, one should proceed with caution.  From some versions of the Precautionary Principle, then, one can argue that the construction of the radar facility should be halted until conclusive evidence can be uncovered proving that exposure to EMFs would not be harmful.  </para>
    <para id="import-auto-idm567873408">At the same time that this debate was taking place within Puerto Rico, the PBS series, <emphasis effect="italics">Frontline</emphasis>, broadcast a documentary over the controversy surrounding EMFs  (June 13, 1995: <emphasis effect="italics">Currents of Fear</emphasis>).  They summarized different risk assessment studies carried out to help decision-makers in the government decide on whether or not to regulate activities that expose the public to EMFs.</para>
    <para id="import-auto-idm405114016">June 13, 1995.  Currents of Fear.  Frontline, June 13, 1995. Season 13, Episode 19.  Episode no longer available but has been placed on YouTube: <link url="https://www.youtube.com/watch?v=rMqNoj0Ne6U"><emphasis effect="underline">https://www.youtube.com/watch?v=rMqNoj0Ne6U</emphasis></link></para>
    <list id="import-auto-idm572779312" list-type="bulleted">
      <item>The Frontline documentary cited an <emphasis effect="bold">epidemiological</emphasis> study carried out in Sweden.  This study compared a population exposed to EMFs to one not exposed and found a risk ratio of four; the exposed population contained four times the incidents of illnesses such as leukemia when compared to those unexposed to EMFs.  This risk ratio is considered significant by some but falls below the levels found in studies of cigarette smokers or workers exposed to asbestos; both showed risk ratios from 10 to 20.  This lends credibility to the claims that exposure to EMFs presents no significant risk to public health. </item>
      <item>The Illinois Institute of Technology constructed a “rodent electromagnetic exposure facility” and set about testing some 3000 rodents exposing them to differing levels of EMFs; a control group received no exposure while others received from 20 to 10,000 milligauss of exposure.  Several studies were carried out: fetal abnormality studies, reproductive studies, cancer studies using cancer-prone mice, an immunological study, and a study into the chronic effects of lifetime exposure; in short, scientists attempted to explore a wide variety of possible mechanisms through which EMFs could cause cancer.  All of these turned out negative.  These studies, called <emphasis effect="bold">animal bioassays</emphasis>, require two projections, one from animal physiology to human physiology and another from intensive short term exposures to less intensive exposures over much longer periods.  Had the high intensity exposures shown significantly higher incidences of the targeted disease than the control group, then further studies would have been carried out to search for a causal mechanism to explain the correlation. “Currents of Fear” outlined different possible causal mechanisms including whether EMFs could “break or rearrange” cell DNA or whether they could stimulate and activate cancer genes.  </item>
    </list>
    <para id="import-auto-idm412078768"/>
    <para id="import-auto-idm580887408">Both studies give rise to uncertainties.  In epidemiological studies, uncertainty arises from the difficulty of finding stable populations of exposed individuals to compare with stable populations of unexposed individuals.  People move about and rarely stay put long enough to allow the illnesses caused by exposure to become manifest.  In animal bioassays, uncertainty arises from the projection from animal physiology to human physiology and from the projection of an intense exposure to the risk factor over a short time to a less intense exposure over a longer time.</para>
    <para id="import-auto-idm408576896">Risk assessment studies in general raise two more uncertainties: whether the harm under study will actually occur and who out of the many exposed will be harmed. Uncertainty in risk assessment raises ethical concerns over how it should be distributed and who should bear the burden of proof in a regulatory debate.  If one places the burden of proof on those who advocate taking the risk, then proponents would have to prove the activity safe before it could be carried out.  If one places the burden of proof on those who would stop or regulate the activity, then <emphasis effect="italics">they</emphasis> would have to prove the product or activity unsafe.  Overregulation can diminish well-being by prohibiting promising activities that pose minimal risks.  Under-regulation harms well-being by allowing activities that expose individuals to unacceptable  risks that are often inequitably distributed.  How we distribute the burden of uncertainty has strong ethical implications; it reflects our values on taking risks as well as how to distribute fairly the risks and benefits associated with the project or activities under consideration.  How we respond to uncertainty has especially strong implications for social justice.  </para>
    <para id="import-auto-idm659319456"/>
    <para id="import-auto-idm360646016">We accept risks all the time.  Everyday activities like driving cars bring with them significant risks that we, nevertheless, deem acceptable.  How do we, then, ethically determine the levels of acceptable risk?  Such decisions might be allocated to the experts who carry out the scientific studies (epidemiological studies or animal bioassays) that assess risk and assign probabilities of harm.  Or, should this prove paternalistic, we might adopt procedures that give the public more voice in determining acceptable risk, even if this deviates from scientific risk assessment.  This was the purpose behind the public hearings held in Lajas, Puerto Rico; these hearings gave opponents to the construction of the radar facility a chance to make their case.  But, again, <emphasis effect="italics">risk perception</emphasis> is often at variance with <emphasis effect="italics">expert risk assessment</emphasis>.  Can this variance be attributable to the irrationality of the public, i.e., its propensity to be carried away by emotion and imagination?  </para>
    <para id="import-auto-idm504140752">Another factor arises in debates over risk: eliminating or reducing risk is difficult and often expensive.  Driving a tank is safer than driving a car but tanks are unaffordable and slow; we trade off the additional risks of driving cars for the clear benefits of speedy, comparatively inexpensive, and comfortable transportation.  Hence, when ethicists turn to defining safety, they do not define it as <emphasis effect="italics">zero</emphasis> risk but as <emphasis effect="italics">acceptable</emphasis> risk.  For example, according to Martin and Schinzinger, “<emphasis effect="bold">A thing is safe if, were its risks fully known, those risks would be judged acceptable by a reasonable person in light of settled value principles</emphasis>” (Intro to EE 109 Martin and Schinzinger).  Indeed, as we will see below, the public makes use of a broader perspective on risk that includes social, ethical, and environmental value.  For some, this broader perspective appeals to a different rationality that, in some senses, rivals the narrower, scientific, and technical perspective (Sunstein and Slovic).  </para>
    <para id="import-auto-idm410156480">
      <emphasis effect="bold">What you need to know</emphasis>
    </para>
    <para id="import-auto-idm652737136">Risk emerges out of fear.  Practices centering around risk assessment, management, perception, and communication draw upon theoretical frameworks that can be used to guide and regulate fear so that it is felt on the right occasions, to the right degree, and in the appropriate circumstances (NE 1125b 32-34).  (Find the reference in Aristotle’s NE) Fear consists of a series of appraisals or judgments of a future impending object’s impact on an individual’s well-being.  Because fear consists of appraisals or judgments, it is cognitive.  Furthermore, because it is cognitive, it can be true or false as well as rational or irrational; it can effectively guide us as we enter a world of threatening objects but it can also misfire causing us to act recklessly when caution is warranted or timidly in situations calling for bold and decisive action.  The concept of risk and its associated dimensions (risk perception, risk assessment, risk management, and risk communication) provide us with tools for shaping and directing the basic emotion of fear (<emphasis effect="bold">Acceptable Evidence</emphasis>).  When guided by a robust conception of risk, fear is steered away from extremes that misinform appraisal and focuses on the mean.  This centering on the mean (and avoiding the extremes of excess and defect) promotes well-being.  </para>
    <para id="import-auto-idm621114096">We begin by examining the general characteristics of fear as an emotion.  Then we will look at the role the emotion fear plays in the virtue that many call moral courage.  For Aristotle this virtue hits the mean between the extremes; for MacIntyre, it brings about habits and dispositions that help individuals contribute to the essential goods of a practice or profession.  We will then outline various practices associated with risk that help steer fear in the right direction.  Finally, we will look at the controversial Precautionary Principle.  This notion has several different versions; those that best steer fear toward promoting well-being lie between strong and weak versions.  Fear plays an essential role in our day-to-day lives and these theoretical perspectives  help keep this powerful emotion on the right track.  </para>
    <para id="import-auto-idm513558384">
      <emphasis effect="bold">An Appraisal Theory of the Emotion of Fear </emphasis>
    </para>
    <para id="import-auto-idm660522048">These four propositions summarize fear as an emotion from the standpoint of the appraisal theory:</para>
    <para id="import-auto-idm404968400"><emphasis effect="italics">1. Definition.  </emphasis>According to Aristotle, “Fear may be defined as a pain or disturbance due to a mental picture of some destructive or painful evil in the future” (Rhetoric, 1382a20, loc 33978).  Martha Nussbaum provides a different translation in <emphasis effect="bold">Monarchy of Fear</emphasis>, page 23: “Aristotle defined fear as pain at the seeming presence of some impending bad thing combined with a feeling that you are powerless to ward it off.”  To develop this notion of fear, fear’s object will be outlined, its appraisals stated, and the correlative virtue will be clarified both as the mean between the extremes and as habits and dispositions that contribute to engineering practice.  </para>
    <para id="import-auto-idm413104240"><emphasis effect="italics">2. Fear as an emotion is an intentional state of mind.</emphasis> According to Martha Nussbaum, "emotions “imply intentional thought or perception directed at an object (as perceived or imagined by the person who has the emotion) and some type of evaluative appraisal of that object made from the agent’s own personal viewpoint” (Nussbaum, Anger, Appendix A, loc. 5440). The objects intended by emotions differ from one another in terms of <emphasis effect="bold">temporality</emphasis> (past, present, future), <emphasis effect="bold">valence</emphasis> (a positive or negative impact on well-being), and <emphasis effect="bold">modality</emphasis> (the object is possible, actual, or necessary). Turning to fear, its temporality is the <emphasis effect="bold">future</emphasis>, its valence <emphasis effect="bold">negative</emphasis> in that the object threatens to diminish the emoter’s well-being, and the danger it represents remains a <emphasis effect="bold">possibility</emphasis>.  </para>
    <para id="import-auto-idm731754816">3. <emphasis effect="italics">Fear as an emotion is composed of appraisals (or judgments) that assess the impact of the emotion's object on the well-being of the individual having the emotion and provide the emotion with its cognitive content</emphasis>. According to Nussbaum (UT 28), “[i]n order to have fear--as Aristotle already saw--I must believe that bad events are impending; that they are not trivially but seriously bad; and that I am not entirely in control of warding them off.” These beliefs are judgments or appraisals of the impact of the object of the emotion on the well-being of the emoter.  They are also necessary constituents of emotions. For example, when I believe that “bad events are impending” and “that I am not entirely in control of warding them off” then I am experiencing fear.  These appraisals may be false or irrational.  I may be mistaken and think I perceive a threat when there isn’t one; or I construe a threat as sizable when it is actually trivial.  I may also be mistaken in what I consider essential to my well-being.  Emotions are fallible in that their constitutive appraisals may be false or irrational.  But they are corrigible; my fear is responsive to standards of truth and rationality, and, in general, emotions are, as Aristotle would put it, responsive to reason.  I can bring my emotions into the light of reflection and assess their appraisals by holding these up to standards of truth and rationality.  </para>
    <para id="import-auto-idm584541776">An emotion misfires when its constitutive appraisals misconstrue the intentional object or mischaracterize its impact on well-being. Martha Nussbaum, in <emphasis effect="bold">Political Emotions</emphasis>, identifies the different ways in which fear’s appraisals can “misfire.”  (She derives these from Aristotle’s discussion of how speakers can persuasively appeal to an audience’s emotions through arguments that address the appraisals that constitute these emotions.)  Fear can lead us astray when we have … (PE 321)</para>
    <para id="import-auto-idm378232592">“misidentified the threat”</para>
    <para id="import-auto-idm616619024">“misestimated its size”</para>
    <para id="import-auto-idm610351152">rendered judgments that are “right about the threat but wrong about who caused it”</para>
    <para id="import-auto-idm596475312">formed a “conception of …well-being that is off-kilter.”  For example, Nussbaum holds that one might construe well-being too narrowly by reducing well-being in general to the well-being of one’s particular group or tribe.</para>
    <para id="import-auto-idm606760304">So fear may lead the residents of Lajas (1) to “misidentify the threat” of radar facilities (radar facilities are harmful but not because the EMFs they produce cause leukemia), (2) to “misestimate” the size of the threat (EMFs do cause leukemia but not the small quantities generated by radar facilities), (3) to be “right about the threat but wrong about [its] cause” (leukemia is a threat but it is not caused by EMFs) and (4) to fail to appreciate the risks of EMFs because their “conception of...well-being ...is off-kilter.” (Proponents of the radar facilities may believe the funds it will bring to Lajas will contribute to the community’s well-being without factoring in the health risks the facility will bring along with its moral harms). </para>
    <para id="import-auto-idm865523968">In a word, whether or not the fear experienced by participants in the public hearings is warranted depends on the risks the radar facility poses to community health and well-being.  </para>
    <para id="import-auto-idm505136416"><emphasis effect="italics">4. Correlative Virtue</emphasis>.  Fear works best when integrated into “acquired habits of understanding, perception, emotion, and behavior that promote the welfare of their possessor or of the community, and ideally of both (Andre, Worldly Virtue, 6).  The virtue of fear can be unpacked in two ways.  One, following Aristotle, characterizes the virtue of fear as the mean between the extremes of excess and defect.  Too much fear leads to the vice of cowardice while too little fear leads to the vice of recklessness.  Another way to understand virtue is that set of “acquired habits” that promote the internal goods of a practice or profession.  This view, held by Alasdar MacIntyre, would place fear in the context of the practice of determining and managing risk viewed as the probability of harm.  The different dimensions of risk determination and management would provide guidance to fear as this emotion uncovers potentially dangerous objects, assesses their impact on the value of well-being, and motivates properly responsive action, i.e., avoiding risky activities and taking measures to minimize and control the risks posed.  </para>
    <para id="import-auto-idm570526160">Let’s approach this more systematically.  The excellence which guides or steers fear can be understood through two different, theoretical approaches to virtue, one elaborated by Aristotle, the other by Alasdar MacIntyre.</para>
    <para id="import-auto-idm434712288">1. Aristotle's full definition of virtue is "<emphasis effect="italics">a state of character concerned with choice, lying in a mean, i.e. the mean relative to us, this being determined by a rational principle, and by that principle by which [a person] of practical wisdom would determine it</emphasis>." (Ross's translation in Nichomachean Ethics, 1106b, 36.).  Thus, moral courage is not zero fear but, the proper amount of fear the mean between recklessness (too little fear) and cowardice (too much fear).  The Precautionary Principle can be presented in this context as a theoretical tool that can guide fear toward the virtuous mean.  Properly formulated--a formulation that avoids the extremes of its strong and weak versions--the Precautionary Principle will use fear as a motivational tool that will help us avoid the extremes of over and under regulation.</para>
    <para id="import-auto-idm411687488">2. Alasdair MacIntyre provides a different approach to virtue.  For him, “<emphasis effect="italics">A virtue is an acquired human quality the possession and exercise of which tend to enable us to achieve those goods which are internal to practices and the lack of which effectively prevents us from achieving any such goods</emphasis>” (AV ?).  Thus, for MacIntyre, a virtue is a constellation of attitudes or emotions and dispositions that stand to bring about the internal goods of a practice.  Engineers and regulators have posed a series of risk-related concepts and practices that help guide fear toward well-being.  <emphasis effect="bold">Risk assessment</emphasis> deploys scientific procedures that calculate the probability of harm within acceptable parameters of uncertainty.  <emphasis effect="bold">Risk perception</emphasis> provides insight into how non-experts (members of the general public) perceive risk.  This perception relies on emotion and imagination.  Emotions, especially fear, help us attend to the values and moral salience embedded in our concrete circumstances (Roeser).  How we perceive and attend risk can also be informed by <emphasis effect="bold">risk communication</emphasis> that incorporates elements of public dialogue and democratic deliberation.  Risk communication helps generate and validate informed consent on the part of risk takers; it emphasizes communicating risk in a manner that is informative, comprehensible, and non-paternalistic.  It also brings to the surface the mental heuristics we use to highlight and assess risk.  Risk communication (and perception) understand the role that heuristics play in the framing of risk.  Among these heuristics are the availability heuristic, probability neglect, loss aversion, benevolence of nature, and system neglect (Sunstein, Laws of Fear, ?).  Risk communication is the the nuanced process of communicating complex risk information to non-experts who must process this information in their deliberations about risk acceptability.  Finally, <emphasis effect="bold">risk management</emphasis> is the political and social process of putting all of this together into a collective and informed decision as to the acceptability of a given risk in terms of settled, widely shared value commitments.  </para>
    <para id="import-auto-idm650621872">This process (the risk process) provides in its totality a series of practices and concepts that function as the virtue of fear (or moral courage) in MacIntyre’s sense.  Here, fear “<emphasis effect="italics">enable[s] us to achieve those goods which are internal to practices”</emphasis>;<emphasis effect="italics"/>fear brings our attention to matters salient to well-being, signals the value of well-being, and motivates action that contributes to well-being.  </para>
    <para id="import-auto-idm663508176">
      <emphasis effect="bold">Glossary of Concepts for Risk and the Precautionary Principle</emphasis>
    </para>
    <para id="import-auto-idm411957536">In the previous section, several concepts were used that require more careful definition and exposition.  This section will provide that clarification.</para>
    <para id="import-auto-idm413377280">
      <emphasis effect="italics">Generic version of the Precautionary Principle  </emphasis>
    </para>
    <para id="import-auto-idm617247200">Cass Sunstein provides a generic version that captures the central features of the precautionary principle: <emphasis effect="italics">“regulators should take steps to protect against potential harms, even if causal chains are unclear and even if we do not know that those harms will come to fruition.” </emphasis> The PC is triggered when individuals are faced with significant risks (probabilities of harm).  Lack of knowledge, especially knowledge of causal chains, is not an excuse for setting aside regulation.  This version roughly steers fear between the extremes of excess and defect; it avoids excessive fear of the new activity, product, or substance but allows enough fear to highlight key risks.  </para>
    <para id="import-auto-idm510799200">
      <emphasis effect="italics">Weak version of the precautionary principle </emphasis>
    </para>
    <para id="import-auto-idm445843280">On one end of the continuum between strong and weak versions of the PC, Cass Sunstein cites the 1992 Rio Declaration as an example of the <emphasis effect="bold">weak version</emphasis> which can suppress helpful fear and leads to under regulation: <emphasis effect="italics">“where there are threats of serious or irreversible damage, lack of full scientific certainty shall not be used as a reason for proposing cost-effective measures to prevent environmental degradation.”</emphasis>  (Sunstein 18)  Sunstein has in mind risks such as those posed by climate change.  Climate “deniers” use uncertainty as an excuse for setting aside regulatory action.  Since we cannot prove that a particular activity should be regulated because it contributes to climate change, and the burden of proof is on the individual who wishes to regulate the activity, the default is to go ahead with the activity.  Do it unless it has been conclusively proved harmful. </para>
    <para id="import-auto-idm455268544">Strong version of the precautionary principle  </para>
    <para id="import-auto-idm515400976">Dr. Brant Blackwelder from Friends of the Earth provides an example of the strong formulating of the precautionary principle (according to Sunstein): <emphasis effect="italics">“when there is a risk of significant health or environmental damage to others or to future generations and when there is scientific uncertainty as to the nature of that damage or the likelihood of the risk, then decisions should be made so as to prevent such activities from being conducted unless and until scientific evidence shows that the damage will not occur.”</emphasis>  This strong version blocks an activity unless it can be proven conclusively safe and free of risk.  The strong version, thus, sets the bar too high at zero or near zero risk.  </para>
    <para id="import-auto-idm448743312">Table comparing strong and weak versions: </para>
    <figure id="import-auto-idm744796880">
      <media id="import-auto-idm508750208" alt="">
        <image mime-type="image/png" src="image1.png" height="225" width="624"/>
      </media>
    </figure>
    <para id="import-auto-idm454132384">
      <emphasis effect="bold">Glossary of concepts associated with fear and risk:</emphasis>
    </para>
    <list id="import-auto-idm741986832" list-type="enumerated" number-style="arabic">
      <item><emphasis effect="bold">Safety </emphasis>is essentially acceptable risk.  For example, Martin and Schinzinger define safety as acceptable risk for engineers in the following formulation: <emphasis effect="italics">“A thing is safe if, were its risks fully known, those risks would be judged acceptable by a reasonable person in light of settled value principles.”</emphasis> This account of safety requires an orderly public dialogue among reasonable stakeholders who share certain “settled” value principles.  </item>
    </list>
    <list id="import-auto-idm396623744" list-type="enumerated" number-style="arabic">
      <item><emphasis effect="bold">Risk Assessment</emphasis>: Risk assessment is the scientific determination of the probability of harm.  Examples of risk assessment include animal bioassays and epidemiological studies.  Risk assessment studies, although scientific, still issue in uncertainties that cannot be completely eliminated.  How this uncertainty is dealt with raises important ethical issues.  For example, deciding who should bear the burden of this uncertainty and who should reap its benefits raises issues in distributive justice.  Another important consideration is the integrity of the process used to conduct a risk assessment study.  At the very least it should be guided by what Office of Research Integrity manual on research ethics terms the four <emphasis effect="bold">epistemic values</emphasis> of scientific research: <emphasis effect="bold">honesty</emphasis>, <emphasis effect="bold">accuracy</emphasis>, <emphasis effect="bold">efficiency</emphasis>, and <emphasis effect="bold">objectivity</emphasis>.  </item>
    </list>
    <para id="import-auto-idm416607232"/>
    <list id="import-auto-idm403342352" list-type="enumerated" number-style="arabic">
      <item><emphasis effect="bold">Risk</emphasis><emphasis effect="bold">Perception</emphasis>.  This concerns the way in which the public comes to perceive and qualitatively assess risk.  There are two broad positions taken by those who do research in this area.  In the <emphasis effect="bold">Theoretical Position</emphasis>, risk perception is considered irrational because it is driven by emotion, and emotion is irrational.  Proponents argue that experts must take a paternalistic attitude toward the uninformed public whose perception of risk is irrational.  The <emphasis effect="bold">Participatory Position</emphasis> shares with the Theoretical Position the view that the public’s perception of risk is irrational because, among other things, it is tainted with emotion.  Nevertheless, regulators, even experts, must give way to the public’s perception of risk in a democratic system.  Risk assessors must either persuade the public to accept scientific results or, failing this, embrace the public’s declaration however irrational (See Roeser).</item>
    </list>
    <para id="import-auto-idm522236000">There are other views on risk perception that deny to different degrees its irrationality and the irrationality of its emotion-laden judgments.  Paul Slovic argues that the public perception of risk represents an alternative—or even rival—rationality that should be taken into account for two reasons.  First, it provides a richer standpoint than scientific risk assessment in that it includes normative appraisals, i.e., provides a value-laden description.  Second, it is a rival rationality because it filters risk through discernable frameworks.  These frameworks make the public’s perception of risk predictable, and this predictability render the public’s perception of risk rational.  For example, risks are perceived as more acceptable if they are voluntary, present benefits that outweigh costs, allow for control, are relatively free of negative emotional concomitants (dread and unknown factors), are old rather than new, and are known rather than fraught with uncertainty. (See Roeser).  </para>
    <list id="import-auto-idm582488064" list-type="enumerated" number-style="arabic">
      <item><emphasis effect="bold">Risk Communication</emphasis>: This dimension focuses on how to communicate risk information to risk bearers in order to facilitate distributive justice, free and informed consent, and due process.  Responsible risk communication draws upon the ability to translate scientific risk assessment information into non-technical terms.  Analogies and comparisons help with this process, as does the use of concrete language.  It is also important to make good use of images, metaphors, narrative, and metonymy.  Finally, risk communicators must respect the public’s right of free and informed consent.  This breaks down into the special attention that must be paid to information, comprehension, and voluntariness (See Belmont Report): </item>
    </list>
    <list id="import-auto-idm411412912" list-type="bulleted">
      <item><emphasis effect="italics">Information</emphasis>.  Risk communicators are responsible for providing the public with information that is complete and trustworthy.  This requires fulfilling the epistemic values of scientific research mentioned above, namely, honesty, accuracy, efficiency, and objectivity.  It also requires that the risk communicator be free of interests that interfere with the full communication of risks associated with a project.  For example, individuals advocating the radar facility in Lares may communicate tainted or incomplete information if their professional judgment is deflected by benefits they stand to gain with the construction and operation of this facility.  Such interests may negatively affect risk communication even if they do not consciously intend this.</item>
      <item><emphasis effect="italics">Comprehension</emphasis>.  The information communicated to the risk bearer must also be presented in a way than can be comprehended by the risk bearing public.  This includes providing listeners with concrete examples, trustworthy analogies, clarifying metaphors, and helpful similes.  The risk communicator should empathize with the risk bearer; this helps her to provide pertinent information and provides insight into how to make this information comprehensible.  For example, individuals discussing the safety of a nuclear power plant should be prepared to answer questions such as whether they would be willing to live next door to this plant.  Through empathy, the communicator places herself into the standpoint of the recipient of the information; she is able to view the information and its emotional impact from this standpoint.  Empathic insight also motivates the risk communicator to go beyond statements of probability to a concrete portrayal of the existential import of the proposed risks.  </item>
      <item><emphasis effect="italics">Voluntariness</emphasis>.  Special effort should be made to avoid presenting information in a way that is coercive, deceptive, or manipulative.  A major pitfall here is the temptation for the risk communicator to take the position of the expert and adopt a paternalistic attitude toward the public.  Behavioral economists do this when they over-emphasize how risk perception is driven by certain mental heuristics like the availability heuristic and probability neglect.  Treating these heuristics only as filters that bias risk perception leads to a paternalistic, I-know-better attitude.  Risk communicators should not shun emotions but should avoid communications that distort the appraisals these emotions are based on.  Through the study of rhetoric we learn how to persuade an audience by appealing to the appraisals or judgments their emotions are based on.  But this persuasion should deploy means that do not cause these appraisals to become distorted or misinformed.  Appeals to emotion can and should be rational and truthful.  Those resorting to irrationality and falsehoods undermine the voluntariness of the act of communication.</item>
    </list>
    <para id="import-auto-idm586584288">Ilse Oosterlaken provides a good example of the role of values and emotions in risk communication when she discusses risk communication in the context of proposed wind turbine farms.  She first of all provides evidence that those opposing wind turbines are selfish; they are not motivated by NIMBY or “not in my backyard.”  Instead the acceptability of wind farms depends on key moral values such as distributive justice, procedural justice, trust, and aesthetic values.  To take one instance, a public will oppose a wind farm if the benefits and burdens of this technology are distributed unfairly.  If the public is going to be asked to bear the costs of such a farm (distortion of landscape) then they are also entitled to benefits that outweigh these costs (reduced energy costs).  Oosterlaken argues that value sensitive design is important here; because wind turbine technology is value laden, designers should make special efforts to instantiate positive moral and prudential values.  Value sensitive design includes a values discovery phase where designers uncover and locate values important to users and other stakeholders.  Participatory design where users and other stakeholders participate in the design process from the beginning can provide a complimentary means of embedding key moral and prudential values into the resulting technological artifacts.  They also provide means of fitting the artifact to the surrounding socio-technical context.  </para>
    <para id="import-auto-idm864768048"><emphasis effect="bold">A List of Mental Heuristics</emphasis> (provided by Cass Sunstein in <emphasis effect="italics">The Laws of Fear</emphasis>)</para>
    <para id="import-auto-idm631973888">Closely related to risk perception and risk communication is the influence of <emphasis effect="bold">heuristics</emphasis> on the perception (and appraisal) of risk. Cass Sunstein provides a useful list of these heuristics, many of which were discovered by Tversky and Khanaman.  What is important is that these heuristics often deflect our perception of risk away from the results of scientific risk assessment.  While experts treat this deflection as a source of misconception and error, others argue that it poses a rival rationality where the assessment of risk takes place from a broader, value-laden perspective.  In other words, these heuristics can mislead because they ignore statistics and probability but they also can enrich the process by including values that are routinely passed over by the narrowly technical risk assessment process.  Here are a list of heuristics that together pose a rationality that rivals that of technical risk assessment.  (list taken from Sunstein, Laws of Fear.)</para>
    <list id="import-auto-idm345427008" list-type="bulleted">
      <item><emphasis effect="bold">Availability Heuristic</emphasis>: “examples and models widely, publicly shared are used to simplify and frame a risk especially its magnitude”</item>
    </list>
    <list id="import-auto-idm468896736" list-type="bulleted">
      <item><emphasis effect="bold">Probability Neglect</emphasis>: “[S]trong emotions cause individuals to fail to consider probability.”  For example, in hope hope: “vivid images of good outcomes will crowd out considerations of probability” while with fear “people focus on one emotionally gripping outcome among a large set of possibilities.”</item>
      <item>In <emphasis effect="bold">Loss Aversion</emphasis>, “a loss from the status quo is seen as more undesirable than a gain is seen as desirable.”  This heuristic cause us to “downplay potential gains” and to “fixate on potential losses.”  It also results in our tolerating familiar over unfamiliar risks</item>
      <item>The<emphasis effect="bold"> Benevolence of Nature </emphasis>heuristic assumes that “nature is essentially benign and … human intervention is likely to carry risks.”  Thus, it leads to the overregulation of pesticides (we refrain from using DDT to kill malaria-carrying mosquitos).  On the other hand, it also leads us to “underestimate the risks of natural carcinogens” (we neglect the risk of radon gas in our homes).</item>
      <item>Finally, in<emphasis effect="bold"> System Neglect </emphasis>risks do not occur in isolation but in a system and in conjunction with other risks.  These interact in such a way that addressing one risk and attempting to reduce it may inadvertently increase another risk with which it interacts.  This is especially the case in addressing a complex problem such as climate change which harbors several conflicting risks and is also plagued with problems arising from the distribution of risks and benefits.  People tend to take a given risk out of its context.  They solve the problem it poses but miss how it interacts with other risks present in the system.</item>
    </list>
    <para id="import-auto-idm521216144">The Precautionary Principle has an important role to play in regulation and in relation to complex system-based problems such as climate change.  But different heuristics of fear such as the availability heuristic and probability neglect lead us to overreact to relatively minor risks and underact to other greater risks.  As a result, it is beneficial to look in more detail at risk assessment itself. </para>
    <para id="import-auto-idm698094192">Ethics enters into the picture as stakeholders negotiate how to deal with and distribute this uncertainty. Responsible risk practice requires integrating the conflicting values and interests of the involved stakeholders in assessing, communicating, perceiving, and managing risk. It also requires a basis of trust that is difficult to build up given the diverse players that make up the risk taking and bearing situation. </para>
    <para id="import-auto-idm601605136">
      <emphasis effect="bold">What you are going to do</emphasis>
    </para>
    <para id="import-auto-idm571222144">
      <emphasis effect="bold">1. The Lajas Radar Facility</emphasis>
    </para>
    <para id="import-auto-idm617833200">Resolved: The radar project proposed near Lajas in the mid 1990s should be halted because of the risks posed by exposing local residents to electromagnetic fields.  This decision is supported by the Precautionary Principle and by sound, scientific risk assessment.  </para>
    <list id="import-auto-idm469816848" list-type="bulleted">
      <item>Refer to the case described above and to the Frontline documentary, “Currents of Fear.”</item>
      <item>What roles should the public and risk assessment experts play in the determination of whether this project poses “acceptable risk?”</item>
    </list>
    <para id="import-auto-idm672983408">
      <emphasis effect="bold">2. Energy Technologies for Puerto Rico</emphasis>
    </para>
    <para id="import-auto-idm508215264">Assess the following technologies for generating energy in Puerto Rico in the aftermath of Hurricane Maria.  </para>
    <list id="import-auto-idm719462080" list-type="bulleted">
      <item>Oil <list id="import-auto-idm411035520" list-type="bulleted"><item>Palo Seco and Aguirre facilities</item><item>Refinery Complex (CORCO or Commonwealth Oil Refining Company)</item><item>Catano Refinery (Formerly of Gulf Oil Corporation) </item></list></item>
      <item>Natural Gas <list id="import-auto-idm403566144" list-type="bulleted"><item>Gaso Ductos del Sur</item><item>Via Verde</item></list></item>
      <item>Eolic Power<list id="import-auto-idm446141504" list-type="bulleted"><item>Consult Oosterlaken, “Applying Value Sensitive Design (VSD) to Wind Turbines and Wind Parks: An Exploration.”  Science and Engineering Ethics (2015) 20: 359-379.  </item></list></item>
      <item>Solar Energy (e.g., solar panels).  </item>
    </list>
    <para id="import-auto-idm463209280">In making your comparison, begin with the distinction between hard and soft power generation technologies.  This distinction was first made by Lovins and has been repeated by Shrader-Frechette.  Soft Path: solar, voltaic, wind turbines, hydro-electric, hydrogen (electrolysis).  Hard Path: oil, coal, gas, nuclear fission, nuclear fusion, incineration.  </para>
    <para id="import-auto-idm620655456">Technology projects proposed for Puerto Rico go through a series of stages: </para>
    <para id="import-auto-idm646632624">(1) project is designed and disseminated to the public through a utility-private industry coalition; it is recommended on economic grounds; </para>
    <para id="import-auto-idm478609104">(2) Project is initially judged acceptable due to the absence of organized opposition.  But opposition will slowly develop as the project is subjected to further scrutiny; </para>
    <para id="import-auto-idm617190608">(3) Opposition strengthens and opponents use different ethical frameworks to give voice to this opposition: social justice, consent and participation, appropriateness, and environmental threats and impacts; </para>
    <para id="import-auto-idm508017200">(4) Debate sharpens as the issue is polarized between proponents and opponents.  Proponents charge that opponents are politically motivated (trying to assert a Marxist ideology or promote Puerto Rican independence) while opponents charge proponents with economic and political agendas (using the energy project and technology to maintain the economic and political status quo which favors business, corporate, and colonial interests).  emerges as the project is subjected to more scrutiny; the debate between proponents and opponents sharpens and polarizes; the project is usually rejected although sometimes accepted.  </para>
    <para id="import-auto-idm617407600">Financial Risk: <emphasis effect="bold">The Wisdom of Finance</emphasis> by Desai</para>
    <list id="import-auto-idm337851568" list-type="bulleted">
      <item>Banks: brokers and blockchain (disruptive technology)</item>
      <item>Regulation (Glass Stegal and structure of FDIC)</item>
      <item>Correlation</item>
      <item>Risk Dispersal  </item>
    </list>
    <para id="import-auto-idm430047312">Technical tools to deal with risk</para>
    <list id="import-auto-idm345065344" list-type="bulleted">
      <item>Credit Default Swaps</item>
      <item>Securitization</item>
      <item>Leverage</item>
      <item>Value at Risk (VaR)</item>
      <item>Gaussian Copula </item>
    </list>
    <para id="import-auto-idm718666048">3. Exercise:</para>
    <para id="import-auto-idm721270304">Assessing different statements of the Precautionary Principle by locating them on a continuum between strong and weak versions.</para>
    <section id="eip-803"><title>Financial Risk</title><para id="eip-999">Since this is a first draft of this module I will be brief on financial risk with the promise to expand upon it later. To begin, there are a series of helpful books that provide good descriptions of what finance is and how it treats risk that have been written for non-experts.  Three come to mind: the Wisdom of Finance by Mihir Desai and Cents and Sensibility by Gary Saul Morson and Morton Schapiro.  Both look at finance from the point of view of the humanities.  This would seem to imply a critical point of view, and both works do provide enough criticism to show ways in which the practice of finance contributed to the financial crisis of 2008.  Nevertheless, the view of finance is made more accessible and more comprehensible by looking for analogies in literature.  (Desai provides fascinating illustrations of options and diversification through the novels of Jane Austin.)  Gillian Tett's older book, Fools Gold, rounds out this series.  Tett is a financial reporter but, as she states in the postscript to her book, she was trained as an anthropologist.  She makes use of these skills to show how derivatives were developed by a group at J.P. Morgan and then misused and abused by the rest of the financial industry.  She provides a useful glossary of key terms and tools in finance some of which I will mention below.</para><para id="eip-430">Critically important to the narrative of finance and the financial meltdown is the repeal of Glass Stegal during the Clinton administration.  This piece of legislation maintained a careful separation of commercial from investment banks.  Commercial banks, insured under the FDIC (the Federal Deposit Insurance Corporation), was required to maintain deposits on hand equal to a certain percentage of debt and loans, this to prevent bank-runs.  On the other hand, investment banks were allowed more room to invest and allowed to leverage themselves more.  In other words, they were allowed to take more financial risks with the promise of greater financial gains.</para><para id="eip-866">M. Desai does a nice job of identifying different practices used by finance to deal with risk.  To illustrate, he uses Jane Austin's novels (e.g., Sense and Sensibility and Pride and Prejudice) to discuss risk in the context of women entering into marriage contracts.  Women during Austin's time were unable to participate in the economy so their choices in marriage were both uncertain and of profound importance to their lives and security.  Consider diversification.  Here Elizabeth Bennett would explore marriage contracts with different individuals looking at men who might be well off (but not of handsome), handsome (but not well off), or philosophical creating the room for deep friendship with their marriage partners.  This could be seen as analogous to diversification in finance; here we handle risk by developing a diversified portfolio.  Or consider options.  Elizabeth might accept a marriage proposal from someone not handsome but wealthy but conditionally.  She might postpone a decision or negotiate a long period of engagement as a way of preserving the possibility of a future, more advantageous proposal from one more handsome.  This is analogous to purchasing an option to buy something at a later date, thus, making a limited commitment to preserve the possibility of a greater investment in the future. Thus, Desai, a finance professor at Harvard, uses risk management in marriage (in Jane Austin's fiction) to illuminate diversification and options in finance.   </para><para id="eip-374">Gillian Tett's study of the financial crisis in 2008, Fool's Gold, shows how the misuse of financial instruments of risk management (such as derivatives, collatoralized debt obligations, credit default swaps, leveraging, and securitization) was one of the major causes of this crisis.  The importance of Tett's discussion is that each of these began as a tool or technology of financial risk management but later was pulled out of its intended context (for which it was designed) and recklessly deployed in other contexts where its ramifications were not explored or understood.</para><list id="eip-918"><title>Select items from Tett's Glossary</title><item>Derivatives: "A financial instrument whose value derives from an underlying asset, most normally commodities, bonds, equities, or currencies." (277)</item>

<item>Credit Default Swaps: "A contract between two parties, where the buyer pays a regular fee to the seller in exchange for a guarantee that he will be compensated in the case of any default on a stipulate piece of debt."  credit default swaps were deployed as sub-prime or risky home mortgages were bundled together with other housing loans.  276</item>

<item>Collateralized Debt Obligations.  "A form of asset-backed security.  They were typically created by bundling together a portfolio of fixed-income debt (such as bonds) and using those assets to back issuance of notes.  Such notes usually carry varying levels of risk." 276</item>

<item>Leverage.  Techniques that can magnify returns (or lo9sses).  The phrase is most commonly used to refer to debt, since the application of debt to a financial structure or strategy can magnify returns and losses." 277</item>

<item>Securitization. A risk dispersal strategy where up to hundreds of mortgages or loans were bundled together and sold as packages to investors.  The high risk sub-prime is, according to the theory, distributed as they are bundled together with less risk loans.  Of course, those preparing these packages or bundles assumed that the loans did not interact or were not correlated.  That is, they assumed that risky loans that defaulted did not bring down with them the stronger, more secure loans. This turned out to be a disastrously incorrect assumption. </item>  
</list><para id="eip-523">Tett also defines the Gaussian Copula in her glossary: "A statistical technique developed by David Li, a former J.P. Morgan analyst, for measuring the level of correlation and default probabilities in CDOs." 277  In "Recipie for Disaster" The Formula that Killed Wall Street (Felix Salmon, Wired, Business, February 2, 2009)the misuse of this financial instrument is blamed for the excessive risks taken by investors whose faith in the calculations of this statistical method covered over the grave risks they were taking.</para><para id="eip-381">There will be more on risk and finance in later versions of this module.</para></section><para id="import-auto-idm742364960">
      <emphasis effect="bold">References</emphasis>
    </para>
    <list id="eip-304" list-type="enumerated" number-style="arabic"><item>“Currents of Fear.”  Frontline, June 13, 1995. Season 13, Episode 19.  Episode found on YouTube: https://www.youtube.com/watch?v=rMqNoj0Ne6U</item>

<item>Andre, J.  (2015). Worldly Virtue: Moral Ideals and Contemporary Life.  Lenham, Md: Lexington Books.</item>

<item>Aristotle. (1941).  The Basic Works of Aristotle, Richard McKeon, ed.  Nicomachean Ethics, translated by W. D. Ross.  1125b 32-34 (loc 24,841).  New York: Random House.</item>

<item>Aristotle. (1941).  The Basic Works of Aristotle, Richard McKeon, ed.  Rhetoric, translated by W. Rhys Roberts.  1382a 20 (loc 33,978).  New York: Random House.</item>

<item>Bilger, B. 2009. “Hearth Surgery: The Quest for a Stove that Can Save the World.” The
New Yorker, December 21, 2009: 84–98.</item>

<item>Brey, P. (2012).  Well-Being in Philosophy, Psychology, and Economics.  in The Good Life in a Technological Age, eds., P. Brey, A. Briggle, and E. Spence.  NY: Routledge: 15-34.</item>

<item>Coeckelbergh, M. (2007).  Imagination and Principles: An Essay on the Role of Imagination in Moral Reasoning.  New York: Palgrave Macmillan.</item>

<item>Coeckelbergh, M.  (2012).  “How I Learned to Love the Robot”: Capabilities, Information Technologies, and Elderly Care.  In: Oosterlaken, I. and Van den Hoven, J. (eds), The Capability Approach, Technology and Design.  Dordrecht: Springer, pp. 77-86.</item>

<item>Crocker, D.  (2008).  Ethics of Global Development: Agency, Capability, and Deliberative Democracy.  Cambridge, UK: Cambridge University Press.</item>

<item>Cruz, J. and Frey, W.  (2013)  Value Integration: From Educational Computer Games to Academic Communities.  IEEE Technology and Society Magazine, Spring 2013: 31-35.</item>

<item>Desai, M. A.  (2017).  The Wisdom of Finance: Discovering Humanity in the World of Risk and Return.  Boston, Mass.: Houghton, Mifflin, Harcourt.</item>

<item>Fernandez-Baldor, A., Hueso, A., and Boni, A.  (2012).  From Individuality to Collectivity: The Challenges for Technology-Oriented Development Projects.  in The Capability Approach, Technology and Design, eds., Oosterlaken and van den Hoven.  Dordrecht: Springer: 135-152.</item>

<item>Fesmire, S.  (2003).  John Dewey and Moral Imagination: Pragmatism in Ethics.  Bloomington, IN: Indiana University Press: 69-91.</item>

<item>Flanagan, M., Howe, D.C., and Nissenbaum, H. (2008). Embodying Values in Technology: Theory and Practice.  in Information Technology and Moral Philosophy, Jerome van den Hoven and John Werkert, eds.  Cambridge: Cambridge University Press: 322-353.</item>

<item>Flanagan, M. amd Nissenbaum, H. (2017). Values at Play in Digital Games.  Cambridge, Mass: MIT Press.</item>

<item>Frondizi, R.  (1963).  What is Value?  La Salle, IL: Open Court Publishing Company.</item>

<item>Heller, R.  (1998).  La Toma de Decisiones.  London, UK: Dorling Kindersley Limited.  Translated by Irene Saslavsky.</item>

<item>Huff, C.W., and Cooper, J. (1987).  “Sex bias in educational software: the effectrs of designers’ stereotypes on the software they design.  Journal of Applied Social Psychology, 17: 519-532.</item>

<item>Johnson, M. (1987).  The Body in the Mind: The Bodily Basis of Meaning, Imagination, and Reason.  Chicago, IL: University of Chicago Press.</item>

<item>Johnson, M.  (1993).  Moral Imagination: Implications of Cognitive Science for Ethics.  Chicago, IL: University of Chicago Press.</item>

<item>Kullman, K. and Lee, N. (2012).  Liberation from/Liberation within: Examining One Laptop per Child with Amartya Sen and Bruno Latour.  in The Capability Approach, Technology and Design, eds., Oosterlaken and van den Hoven.  Dordrecht: Springer: 39-56.</item>

<item>Ladd, J. (1991). Bhopal: An essay on moral responsibility and civic virtue.  Journal of Social Philosophy, 22(1): 73-91</item>

<item>Lazarus, R. S.  (1991).  Emotion and Adaptation.  Oxford, UK: Oxford University Press.</item>

<item>Maxwell. B. (2006).  Naturalized Compassion: A Critique of Nussbaum on Literature as Education for Compassionate Citizenry.  Journal of Moral Education, 35(3): 340.</item>

<item>Mink A., van der Marel, F., Parmar, V., and Kandachar, P.  (2015).  Using the Capability Approach to Detect Design Opportunities.  Design for Sustainable Well-being and Empowerment IISc Press and TU Delft: 283-303.</item>

<item>Morson, G.S., and Schapiro, M.O.  (2017).  Cents and Sensibility: What economics can learn from the humanities.  Princeton, NJ: Princeton University Press</item>

<item>Nussbaum, M. (1997).  Cultivating Humanity: A Classical Defense of Reform in Liberal Education.  Cambridge, Mass.: Harvard University Press.</item>

<item>Nussbaum, M. (2003).  Upheavals of Thought: The Intelligence of Emotions. Cambridge, UK: Cambridge University Press.</item>

<item>Oosterlaken, I., and van den Hoven, J., eds.  The Capability Approach, Technology and Design.  Dordrecht: Springer.</item>

<item>Oosterlaken, I., Grimshaw, D.J., and Janssen, P.  (2012).  Marrying the Capability Approach, Appropriate Technology and STS: The Case of Podcasting Devices in Zimbabwe.  in The Capability Approach, Technology and Design, eds., Oosterlaken and van den Hoven.  Dordrecht: Springer: 113-134.</item>

<item>Oosterlaken, I.  (2015).  Technology and Human Development.  London: Routledge.</item>

<item>Parfit, D. (1984). Reasons and Persons. NY: Oxford University Press: Appendix I, 493.</item>

<item>Piper, A.  (1991).  Impartiality, Compassion, and Modal Imagination.  Ethics, 101(4): 726-757.</item>

<item>Rapp, Christof, "Aristotle's Rhetoric", The Stanford Encyclopedia of Philosophy (Spring 2010 Edition), Edward N. Zalta (ed.).  </item> 	

<item>Rawls, J. (1971).  A Theory of Justice.  Cambridge, Mass.: Harvard University Press: 5, 40-45.</item>

<item>Rittel, H.W.J. and Weber, M. M.  (1973).  Dilemmas in a General Theory of Planning.  Policy Sciences 4: 155-169.</item>

<item>Roberts, R. (2013). Emotions in the Moral Life. New York: Cambridge University Press.  (loc 2645).</item>

<item>Robeyns, I. (2017). Wellbeing, Freedom and Social Justice: The capability approach re-examined.  Cambridge, UK: Open Book Publishers: loc 2518-2953.</item>

<item>Robison, W.  (2017).  Ethics Within Engineering: An Introduction.  London, UK: Bloomsbury Academics: 262.</item>

<item>Roeser, S. (2018).  Risk, Technology, and Moral Emotions.  New York: Routledge.</item>

<item>Roeser, S. (2012).  Emotional Engineers: Toward Morally Responsible Design.  Science and Engineering Ethics, 18: 103-115.</item>

<item>Rios-Velazquez, F., Frey, W., Jaramillo-Giraldo, E., and Echeverry-Solarte, M. (2013). Accepting the likelihood of ambiguity and disagreement on moral matters: Transitioning into the “Gray World.”  Teaching Ethics 13(2): 55-72.</item>

<item>Sagoff, M.  (1988).  The Economy of the Earth: Philosophy, Law, and the Environment.  Cambridge, UK: Cambridge University Press.</item>

<item>Scarantino, A.  (2016).  “The Philosophy of Emotions and Its Impact on Affective Science.” Handbook of Emotions, 4th., Lisa Feldman Barrett, Michael Lewis, and Jeannette M. Haviland-Jones, editors.  London, UK: Guilford Press: loc 353-2153.</item>

<item>Sherman, N. (1997).  Making a Necessity of Virtue: Aristotle and Kant on Virtue.  Cambridge, Mass: Cambridge University Press.</item>

<item>Slovic, P. (1991).  Beyond Numbers: A broader perspective on risk perception and risk communication.  in Acceptable Evidence: Science and Values in Risk Management, eds. R. Hollander and D. Mayo.  Oxford, UK: Oxford University Press: 48-65.</item>

<item>Sunderland, M.E.  (2014).  Taking Emotions Seriously: Meeting Students Where They Are.  Science and Engineering Ethics. 20: 183-195.</item>

<item>Tett, G. (2009.  Fools Gold: How the bold dream of a small tribe at J&gt;P&gt; Morgan was corrupted by Wall Street greed and unleashed a catastrophe.  New York: Free Press.</item>

<item>Urban Walker, M. (2005). Moral Repair: Restructuring moral relations after wrongdoing. 
Cambridge: Cambridge University Press.</item>

<item>Wallach and Allen. (2009).  Moral Machines: Teaching Robots Right from Wrong. Oxford, UK: Oxford University Press.</item>

<item>Werhane, P.  (1999).  Moral Imagination and Management Decision Making.  Oxford UK: Oxford University Press: 69-88.</item>

<item>Whitbeck, C. (1996). Ethics as Design: Doing Justice to Moral Problems.  Hasting Center Report, 26(3): 9-16.</item>

</list></content>
</document>